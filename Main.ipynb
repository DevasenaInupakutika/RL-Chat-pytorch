{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have a GPU?  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\" I have a GPU? \", use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Skip the data Pre-Processing \n",
    "\n",
    "### you already have the pickle files, just run the 2 cells below to collect the 3 pickle files that are the training data, they are just Lang Class instances with the word2index and index2word mappings and n_words for vocab size, the class Lang must be defined before the pickle and populate it with data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Maximum length of the sequences you are mapping \n",
    "MAX_LENGTH = 20 #50\n",
    "MIN_LENGTH = 4 #2\n",
    "\n",
    "# start of sentence and end of sentence indices\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang = pickle.load( open( \"saved_pickle/input_lang_4_20.p\", \"rb\" ) )\n",
    "output_lang = pickle.load( open(  \"saved_pickle/output_lang_4_20.p\", \"rb\" ) )\n",
    "pairs = pickle.load( open( \"saved_pickle/pairs_4_20.p\", \"rb\" ) )\n",
    "\n",
    "# see the way it works\n",
    "\n",
    "#input_lang.n_words, input_lang.word2index[\"froid\"], input_lang.index2word[33]\n",
    "output_lang.word2index[\"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples 525845\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples\",len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dont have to run these, the pre-processing from ../data folder/input-output.txt\n",
    " final outputs of the preprocessing steps, they are just Lang Class instances with the word2index and index2word mappings and n_words for vocab size, the class Lang must be defined before the pickle and populate it with data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(\"newlinechar\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('../data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    '''\n",
    "    Your Preferences here\n",
    "    '''\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "           len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "           len(p[1].split(' ')) > MIN_LENGTH and \\\n",
    "           \"https://\" not in p[1] \n",
    "        \n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False, Filter = False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    if Filter:\n",
    "        pairs = filterPairs(pairs)\n",
    "        print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 622654 sentence pairs\n",
      "Trimmed to 280811 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "input 36663\n",
      "output 38082\n"
     ]
    }
   ],
   "source": [
    "#input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "#print(random.choice(pairs))\n",
    "#input_lang.index2word[15] # input is french\n",
    "\n",
    "#pickle.dump( input_lang, open( \"saved_pickle/input_lang.p\", \"wb\" ) )\n",
    "#pickle.dump( output_lang, open( \"saved_pickle/output_lang.p\", \"wb\" ) )\n",
    "#pickle.dump( pairs, open( \"saved_pickle/pairs.p\", \"wb\" ) )\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('input', 'output', reverse=False, Filter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( input_lang, open( \"saved_pickle/input_lang_4_20.p\", \"wb\" ) )\n",
    "pickle.dump( output_lang, open( \"saved_pickle/output_lang_4_20.p\", \"wb\" ) )\n",
    "pickle.dump( pairs, open( \"saved_pickle/pairs_4_20.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here after you have the pickle files, skip above\n",
    "\n",
    "## Just some Helper functions used in the Main training loop and main model \n",
    "\n",
    "### Example training output\n",
    "\n",
    "time elapsed, estimated time remaining given, and progress %, Loss\n",
    "\n",
    "1m 52s (- 26m 10s) (5000 6%) 2.8937 \n",
    "\n",
    "3m 40s (- 23m 50s) (10000 13%) 2.3437\n",
    "\n",
    "5m 31s (- 22m 4s) (15000 20%) 2.0382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##############  Converts [\" input string \", \" output string \"] (pair) , appends <EOS> index and returns indices ######\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "######## the pair indices are returned as 2 LongTensor Variables in torch #############\n",
    "\n",
    "\n",
    "######## Tells you how long youve been training and how much longer you have left ####\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "######################################################################3\n",
    "\n",
    "############### plot_losses #######################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - The Gated recurrent unit - FYI\n",
    "\n",
    "Here is the way torch formulates each layer of the GRU\n",
    "\n",
    "\\begin{split}\\begin{array}{ll}\n",
    "r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \\\\\n",
    "\\end{array}\\end{split}\n",
    "\n",
    "where h_t is the hidden state at time t, x_t is the hidden state of the previous layer at time t or input_t for the first layer, and r_t, z_t, n_t are the reset, input, and new gates, respectively. σ is the sigmoid function\n",
    "\n",
    "### Instantiation Parameters:\t\n",
    "\n",
    "input_size – The number of expected features in the input x \n",
    "\n",
    "hidden_size – The number of features in the hidden state h\n",
    "\n",
    "num_layers – Number of recurrent layers.\n",
    "\n",
    "bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "\n",
    "batch_first – If True, then the input and output tensors are provided as (batch, seq, feature)\n",
    "\n",
    "dropout – If non-zero, introduces a dropout layer on the outputs of each RNN layer except the last layer\n",
    "p – probability of an element to be zeroed. Default: 0.5\n",
    "\n",
    "bidirectional – If True, becomes a bidirectional RNN. Default: False\n",
    "\n",
    "\n",
    "#### Inputs: input, h_0\n",
    "\n",
    "input (seq_len, batch, input_size): tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See torch.nn.utils.rnn.pack_padded_sequence() for details.\n",
    "\n",
    "h_0 (num_layers * num_directions(2 for bidirectional), batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided.\n",
    "\n",
    "#### Outputs: output, h_n\n",
    "\n",
    "output (seq_len, batch, hidden_size * num_directions): tensor containing the output features h_t from the last layer of the RNN, for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the input, the output will also be a packed sequence.\n",
    "\n",
    "h_n (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t=seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and Decoder in next 2 cells\n",
    "\n",
    "### the class for these models needs to be defined to load parameters into them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers = 3, bidirectional = False):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            num_directions = 2\n",
    "        else:\n",
    "            num_directions = 1\n",
    "        \n",
    "        # make the initial hidden state learnable as well \n",
    "        hidden0 = torch.zeros(self.num_layers*num_directions, 1, self.hidden_size)\n",
    "        \n",
    "        if use_cuda:\n",
    "            hidden0 = hidden0.cuda()\n",
    "        else:\n",
    "            hidden0 = hidden0\n",
    "\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "            \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return self.hidden0.cuda()\n",
    "        else:\n",
    "            return self.hidden0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH, num_layers = 3):\n",
    "        \n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, num_layers = num_layers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        hidden0 = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        \n",
    "        if use_cuda:\n",
    "            hidden0 = hidden0.cuda()\n",
    "        else:\n",
    "            hidden0 = hidden0\n",
    "\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return self.hidden0.cuda()\n",
    "        else:\n",
    "            return self.hidden0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training\n",
    "\n",
    "## trainIters() takes the encoder instance, decoder instance and trains it using the helper function train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH, teacher_forcing_ratio = 0.5, bidirectional = False):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        \n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    if bidirectional:\n",
    "        # sum the bidirectional hidden states into num_layers long cause the decoder is not bidirectional\n",
    "        encoder_hidden = encoder_hidden[:encoder.num_layers, :, :] + encoder_hidden[encoder.num_layers:, : ,:] \n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100,\n",
    "               learning_rate=0.01, teacher_forcing_ratio = 0.5, bidirectional = False,\n",
    "               name = \"noname\", lowest_loss =100, gamma = 0.95):\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    #encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    #decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    escheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=print_every, gamma=gamma) \n",
    "    dscheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=print_every, gamma=gamma) \n",
    "    \n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    lowest_loss = lowest_loss\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        escheduler.step()\n",
    "        dscheduler.step()\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                     encoder_optimizer, decoder_optimizer, criterion, \n",
    "                     teacher_forcing_ratio = teacher_forcing_ratio,\n",
    "                     bidirectional =  bidirectional)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            \n",
    "            if lowest_loss > print_loss_avg:\n",
    "                lowest_loss = print_loss_avg\n",
    "                print(\"new lowest loss, saving...\")\n",
    "                torch.save(encoder.state_dict(), \"saved_params/encoder\"+name+\".pth\")\n",
    "                torch.save(attn_decoder.state_dict(), \"saved_params/attn_decoder\"+name+\".pth\")\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Instantiate The Encoder and Decoder \n",
    "\n",
    "### move the model to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 128#256\n",
    "num_layers = 2#3\n",
    "bidirectional = False#True\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, num_layers = num_layers, bidirectional = bidirectional)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1, num_layers = num_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    attn_decoder = attn_decoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell if you have saved parameters you want to load into the encoder decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder.load_state_dict(torch.load(\"saved_params/encoder.pth\"))\n",
    "#attn_decoder.load_state_dict(torch.load(\"saved_params/attn_decoder.pth\"))\n",
    "encoder.load_state_dict(torch.load(\"saved_params/encoder_2L_h128_uni3.pth\"))\n",
    "attn_decoder.load_state_dict(torch.load(\"saved_params/attn_decoder_2L_h128_uni3.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## call to the MAIN TRAINING LOOP and cell for storing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 37s (- 68m 34s) (10000 10%) 4.9078\n",
      "15m 2s (- 60m 9s) (20000 20%) 4.8423\n",
      "22m 33s (- 52m 37s) (30000 30%) 4.7705\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder, attn_decoder, n_iters = 100000, print_every=10000, \n",
    "           learning_rate=0.001, teacher_forcing_ratio = 0.9,\n",
    "           bidirectional = bidirectional, name = \"_2L_h128_uni3\",\n",
    "           lowest_loss = 4.1, gamma = 0.95) # last loss 4.3393, 16 secs per 100 iters, so ~ 22500 iters/hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to save the results of your training\n",
    "torch.save(encoder.state_dict(), \"saved_params/encoder_2L_h128_uni3.pth\")\n",
    "torch.save(attn_decoder.state_dict(), \"saved_params/attn_decoder_2L_h128_uni3.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inference/Prediction/Chat with me\n",
    "\n",
    "### evaluate() is your main inference function to deploy the encoder-decoder as a chatbot\n",
    "\n",
    "### evaluateRandomly() calls evaluate() to give you a sampling of dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH,\n",
    "             bidirectional =bidirectional):\n",
    "    \n",
    "    \n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    if bidirectional:\n",
    "        # sum the bidirectional hidden states into num_layers long cause the decoder is not bidirectional\n",
    "        encoder_hidden = encoder_hidden[:encoder.num_layers, :, :] + encoder_hidden[encoder.num_layers:, : ,:]\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10, bidirectional = False):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('input from data >', pair[0])\n",
    "        print('output from data=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0], bidirectional = bidirectional)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('bot response <', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input from data > happy independence day .\n",
      "output from data= yeah . happy fourth of july .\n",
      "bot response < i m not going to . . . <EOS>\n",
      "\n",
      "input from data > collision ? with what ?\n",
      "output from data= the page s missing . then their sos was real .\n",
      "bot response < i m not going to . . <EOS>\n",
      "\n",
      "input from data > who is this ?\n",
      "output from data= hello my name is barry egan and i called your service \n",
      "bot response < i don t know . <EOS>\n",
      "\n",
      "input from data > oh yeah i love those . yeah . . . those are funny . . .\n",
      "output from data= well it was really nice meeting you and uh . . . i d better get a cab .\n",
      "bot response < i don t know . <EOS>\n",
      "\n",
      "input from data > cigarettes and beer rule ! huh huh .\n",
      "output from data= yeah ! we re with the bureau of cigarettes and chicks ! we re gonna score !\n",
      "bot response < i m not going to . . <EOS>\n",
      "\n",
      "input from data > is that bad ?\n",
      "output from data= not at all . those are our honeymoon suites .\n",
      "bot response < i don t know . <EOS>\n",
      "\n",
      "input from data > let s hope you make the most of it my boy .\n",
      "output from data= shall we go to my office ?\n",
      "bot response < i m not going to . . <EOS>\n",
      "\n",
      "input from data > what s your twenty ?\n",
      "output from data= quarter mile away . we see the lights . . .\n",
      "bot response < i m not going to . . . <EOS>\n",
      "\n",
      "input from data > i m interested in long term expectations .\n",
      "output from data= it s engineered to last about fifteen years .\n",
      "bot response < i m not going to . . . <EOS>\n",
      "\n",
      "input from data > i knew you d make it ! where s your girl ? didn t she come ?\n",
      "output from data= naw . that s over with .\n",
      "bot response < i don t know . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, attn_decoder,  n=10, bidirectional = bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = what does this mean where are we and where are we going ?\n",
      "output = i m going to be . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADxCAYAAADBVawCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IiIhkqAj4hoqAT4iIiGSoCPiGio/w8o0Eb0BddsIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44a54269b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = why is this happening ?\n",
      "output = i don t know . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADxCAYAAADBVawCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBPiIiJZKgI+IaKn/D1/b1VX8ALd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44a694fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = well me something stupid\n",
      "output = i m not going to . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADyCAYAAABHwd6sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPiKipRLgIyJaKgE+IqKl/j/j+5s/p81rVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44a535f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = you can make it if you try\n",
      "output = i m not going to . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADxCAYAAADBVawCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIloqCT4ioqWS4CMiWurfAVSMjjdepsmvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44af4a66a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bidirectional = False #True\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions, bidirectional = False):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence,encoder, attn_decoder, bidirectional = False):\n",
    "    \n",
    "    output_words, attentions = evaluate(encoder, attn_decoder, input_sentence, bidirectional = bidirectional)\n",
    "    \n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"what does this mean where are we and where are we going ?\",\n",
    "                         encoder, attn_decoder, bidirectional = bidirectional  )\n",
    "\n",
    "evaluateAndShowAttention(\"why is this happening ?\",encoder, attn_decoder, bidirectional = bidirectional)\n",
    "\n",
    "evaluateAndShowAttention(\"tell me something stupid\",encoder, attn_decoder, bidirectional = bidirectional)\n",
    "\n",
    "evaluateAndShowAttention(\"you can make it if you try\",encoder, attn_decoder, bidirectional = bidirectional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TO DO: ####\n",
    "\n",
    "##############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
