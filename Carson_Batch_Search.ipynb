{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have a GPU?  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GLOVE Vectors\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "#For Batching\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\" I have a GPU? \", use_cuda)\n",
    "\n",
    "MAX_SENT_LENGTH = 25\n",
    "min_sent_len = 1\n",
    "min_word_cnt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "glove = vocab.GloVe(name='6B', dim=100)\n",
    "\n",
    "print('Loaded {} words'.format(len(glove.itos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        '''\n",
    "        Store the string token to index token\n",
    "        mapping in the word2index and index2word\n",
    "        dictionaries. \n",
    "        '''\n",
    "        \n",
    "        self.name = name\n",
    "        self.trimmed = False # gets changed to True first time Lang.trim(min_count) is called\n",
    "        self.word2index = {\"<PAD>\" : 0 ,  \"<SOS>\" : 1, \"<EOS>\" : 2 , \"<UNK>\" : 3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.n_words = len(self.index2word) # Count default tokens\n",
    "        self.num_nonwordtokens = len(self.index2word)\n",
    "        self.PAD_token = 0\n",
    "        self.SOS_token = 1\n",
    "        self.EOS_token = 2\n",
    "        self.UNK_token = 3\n",
    "\n",
    "    def index_sentence(self, sentence):\n",
    "        '''\n",
    "        Absorbs a sentence string into the token dictionary\n",
    "        one word at a time using the index_word function\n",
    "        increments the word count dictionary as well\n",
    "        '''\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    \n",
    "    def trim(self, min_count):\n",
    "        '''\n",
    "        Removes words from our 3 dictionaries that\n",
    "        are below a certain count threshold (min_count)\n",
    "        '''\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.n_words = len(self.index2word) # Count default tokens\n",
    "        self.num_nonwordtokens = len(self.index2word)\n",
    "        self.PAD_token = 0\n",
    "        self.SOS_token = 1\n",
    "        self.EOS_token = 2\n",
    "        self.UNK_token = 3\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)\n",
    "            \n",
    "    def unicode_to_ascii(self, s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn')\n",
    "            \n",
    "    def normalize_string(self, s):\n",
    "        s = self.unicode_to_ascii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        s = re.sub(\"newlinechar\", \"\", s)\n",
    "        s = s.replace(\"'\",\"\")\n",
    "        s = s.replace(\".\",\"\")\n",
    "        s = s.replace(\"n t \",\"nt \")\n",
    "        s = s.replace(\"i m \",\"im \")\n",
    "        s = s.replace(\"t s \",\"ts \")\n",
    "        s = s.replace(\" s \",\"s \")\n",
    "        s = s.replace(\" re \",\" are \")\n",
    "        s = s.replace(\"i ve \",\"ive \")\n",
    "        s = s.replace(\" d \",\"d \")\n",
    "        s = ' '.join(s.split())\n",
    "        return s\n",
    "\n",
    "    def filterPair(self, p, max_sent_len, min_sent_len):\n",
    "        \n",
    "        '''\n",
    "        Your Preferences here\n",
    "        '''\n",
    "\n",
    "        return len(p[0].split(' ')) < max_sent_len and \\\n",
    "               len(p[1].split(' ')) < max_sent_len and \\\n",
    "               len(p[1].split(' ')) > min_sent_len and \\\n",
    "               len(p) == 2 and \\\n",
    "               \"https://\" not in p[1] \n",
    "\n",
    "    \n",
    "    def make_pairs(self, path_to_tab_sep_dialogue, \n",
    "                   max_sent_len = 20, min_sent_len = 4):\n",
    "\n",
    "        print(\"making final_pairs list ...\")\n",
    "        lines = open(path_to_tab_sep_dialogue).read().strip().split('\\n')\n",
    "        \n",
    "        final_pairs = []\n",
    "        i = 0\n",
    "        for l in lines:\n",
    "            \n",
    "            pair = [self.normalize_string(sentence) for sentence in l.split('\\t')]\n",
    "            \n",
    "            if self.filterPair(pair,max_sent_len, min_sent_len):\n",
    "                \n",
    "                filtered_pair = []\n",
    "                \n",
    "                for sentence in pair:\n",
    "\n",
    "                    self.index_sentence(sentence)\n",
    "                    filtered_pair.append(sentence)\n",
    "                  \n",
    "                final_pairs.append(filtered_pair)\n",
    "        print(\"number of pairs\", len(final_pairs))\n",
    "        return final_pairs\n",
    "    \n",
    "    def tokens2glove(self, min_word_count,glove, mbed_dim = 50):\n",
    "    \n",
    "        print(\"trimming...\")    \n",
    "        self.trim(min_word_count)\n",
    "        \n",
    "        if glove is None:\n",
    "            glove = vocab.GloVe(name='6B', dim=embed_dim)\n",
    "            print('Loaded {} words'.format(len(glove.itos)))\n",
    "        else:\n",
    "            embed_dim = glove.vectors.size(1)\n",
    "                    \n",
    "        print(\"building embedding from glove...\")\n",
    "        embedding = np.zeros((len(self.index2word), embed_dim)).astype(np.float32)\n",
    "        for i in range(self.num_nonwordtokens):\n",
    "            embedding[i,:] = np.random.uniform(-1,1,embed_dim).astype(np.float32)\n",
    "        for i in range(self.num_nonwordtokens,len(self.index2word)):\n",
    "            if self.index2word[i] in glove.stoi:\n",
    "                embedding[i,:] = glove.vectors[glove.stoi[self.index2word[i]]]\n",
    "            else:\n",
    "                embedding[i,:] = np.random.uniform(-1,1,embed_dim).astype(np.float32)\n",
    "        \n",
    "        return self.index2word, self.word2index, embedding, self.n_words #torch.from_numpy(embeddings).float() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making final_pairs list ...\n",
      "number of pairs 257736\n",
      "trimming...\n",
      "keep_words 28704 / 46316 = 0.6197\n",
      "building embedding from glove...\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LENGTH = 20\n",
    "min_sent_len = 4\n",
    "min_word_cnt = 3\n",
    "lang = Lang(\"chat\")\n",
    "pairs = lang.make_pairs(\"../data/1-25.txt\", \n",
    "                              max_sent_len = MAX_SENT_LENGTH, min_sent_len = min_sent_len)\n",
    "\n",
    "index2word, word2index, embedding, vocab_size = lang.tokens2glove(min_word_cnt ,glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picklefile = (index2word, word2index, embedding, pairs)\n",
    "pickle.dump(picklefile, \n",
    "            open( \"saved_pickle/index2word28704_word2index_embedding_257736pairs.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2word, word2index, embedding, final_pairs  = \\\n",
    "pickle.load( open( \"saved_pickle/index2word28704_word2index_embedding_257736pairs.p\", \"rb\" ) )\n",
    "\n",
    "lang = Lang(\"chat\")\n",
    "lang.index2word = index2word\n",
    "lang.word2index = {**lang.word2index, **word2index}\n",
    "MAX_SENT_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28708, 100) 28708 28708\n"
     ]
    }
   ],
   "source": [
    "print(embedding.shape, len(index2word), len(lang.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########  Converts [\" input string \", \" output string \"] (pair) , appends <EOS> index and returns indices ######\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    '''\n",
    "    account for strings not in the vocabulary by using the unknown token\n",
    "    '''\n",
    "    sentence_as_indices = []\n",
    "    sentence = lang.normalize_string(sentence)\n",
    "    for word in sentence.split(' '):\n",
    "        if word in lang.word2index:\n",
    "            sentence_as_indices.append(lang.word2index[word])\n",
    "        else:\n",
    "            sentence_as_indices.append(lang.UNK_token)\n",
    "            \n",
    "    sentence_as_indices.append(lang.EOS_token)\n",
    "    \n",
    "    return sentence_as_indices\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    '''\n",
    "    add EOS token to sequence of idices and make a column vector\n",
    "    '''\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(lang.EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair,lang):\n",
    "    input_variable = variableFromSentence(lang, pair[0])\n",
    "    target_variable = variableFromSentence(lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "######## the pair indices are returned as 2 LongTensor Variables in torch #############\n",
    "\n",
    "\n",
    "######## Tells you how long youve been training and how much longer you have left ####\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n",
    "\n",
    "######################################################################3\n",
    "\n",
    "############### plot_losses #######################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, embedding,\n",
    "                 num_layers = 3, bidirectional = False, train_embedding = True):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        embedding = torch.from_numpy(embedding).float()\n",
    "        if use_cuda:\n",
    "            embedding.cuda()\n",
    "        self.embedding = nn.Embedding(embedding.shape[0], embedding.shape[1])\n",
    "        self.embedding.weight = nn.Parameter(embedding, requires_grad=train_embedding)\n",
    "        self.gru = nn.GRU(embedding.shape[1], hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            num_directions = 2\n",
    "        else:\n",
    "            num_directions = 1\n",
    "        \n",
    "        # make the initial hidden state learnable as well \n",
    "        hidden0 = torch.zeros(self.num_layers*num_directions, 1, self.hidden_size)\n",
    "        \n",
    "        if use_cuda:\n",
    "            hidden0 = hidden0.cuda()\n",
    "        else:\n",
    "            hidden0 = hidden0\n",
    "\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden):\n",
    "        \n",
    "        if use_cuda:\n",
    "            input_seqs.cuda()\n",
    "        batch_size = input_seqs.size(1)\n",
    "        hidden = self.hidden0.repeat(1, batch_size, 1)\n",
    "\n",
    "        self.embedded = self.embedding(input_seqs)\n",
    "        #self.packed = torch.nn.utils.rnn.pack_padded_sequence(self.embedded, input_lengths)\n",
    "        #output, hidden = self.gru(self.packed, hidden)\n",
    "        output, hidden = self.gru(self.embedded, hidden)\n",
    "        #output, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output) # unpack (back to padded)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        \n",
    "        # ouput (max_len x batch_size x hidden_size)\n",
    "        # hidden ( n_layers * 2(if bidirectional) x batch_size x hidden_size )   \n",
    "        return output, hidden  \n",
    "    \n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return self.hidden0.cuda()\n",
    "        else:\n",
    "            return self.hidden0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if use_cuda:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        #hidden = self.hidden0.repeat(1, batch_size, 1)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N, view is like reshape()\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad a with the PAD symbol\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [lang.PAD_token for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "def random_batch(batch_size):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "\n",
    "    # Choose random pairs\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "        input_seqs.append(indexesFromSentence(lang, pair[0]))\n",
    "        target_seqs.append(indexesFromSentence(lang, pair[1]))\n",
    "\n",
    "    # Zip into pairs, sort by length (descending), unzip\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs = zip(*seq_pairs)\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "    \n",
    "    if use_cuda:\n",
    "        input_var = input_var.cuda()\n",
    "        target_var = target_var.cuda()\n",
    "        \n",
    "    return input_var, input_lengths, target_var, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, \n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          max_length=MAX_SENT_LENGTH ):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([lang.SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "#print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n",
    "#print('encoder_hidden', encoder_hidden.size()) # n_layers * 2 x batch_size x hidden_size\n",
    "\n",
    "# Configure models\n",
    "dropout = 0.1\n",
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "vocab_size = len(lang.index2word)\n",
    "\n",
    "encoder = EncoderRNN(hidden_size, embedding, num_layers = num_layers, \n",
    "                     bidirectional = bidirectional,\n",
    "                     train_embedding = True)\n",
    "\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, vocab_size, \n",
    "                              n_layers = num_layers, dropout=dropout)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carson/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/carson/Courses/NLP/practical-pytorch/seq2seq-translation/masked_cross_entropy.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_flat = functional.log_softmax(logits_flat)\n",
      "/home/carson/Courses/NLP/practical-pytorch/seq2seq-translation/masked_cross_entropy.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 48s (- 1123m 26s) (5 0%) 7.8858\n",
      "one of those outside agitators\n",
      "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "4m 7s (- 819m 24s) (10 0%) 7.6177\n",
      "why should we care ? because love thats why\n",
      "<EOS>\n",
      "5m 26s (- 719m 54s) (15 0%) 6.8275\n",
      "two hundred dollars a toe\n",
      "<EOS>\n",
      "6m 45s (- 669m 46s) (20 1%) 6.5146\n",
      "no youre not but a presence in your house is not something to be taken lightly\n",
      "<EOS>\n",
      "8m 6s (- 639m 58s) (25 1%) 6.6599\n",
      "i think you have the wrong number\n",
      "you <EOS>\n",
      "9m 24s (- 617m 32s) (30 1%) 6.5687\n",
      "i had it coming from someone\n",
      "i i i <EOS>\n",
      "10m 43s (- 602m 4s) (35 1%) 6.6667\n",
      "whats all that wood ?\n",
      "i i i i i i i i i i i i i i i i <EOS>\n",
      "12m 2s (- 590m 7s) (40 2%) 6.5676\n",
      "yes it is would you tell me your name again please ?\n",
      "you you <EOS>\n",
      "13m 18s (- 578m 3s) (45 2%) 6.5986\n",
      "the duke ? what did you do ?\n",
      "i i i i i i i i i i i you you <EOS>\n",
      "14m 36s (- 569m 32s) (50 2%) 6.5689\n",
      "oh angela ! go with these trappers ! theyll lead you safely down the mountain\n",
      "you you you you you you you you you you <EOS>\n",
      "15m 54s (- 562m 30s) (55 2%) 6.5220\n",
      "i wish youd give it a try\n",
      "i i i i i i i i i i i i you you you the the the the the\n",
      "17m 11s (- 555m 58s) (60 3%) 6.4488\n",
      "you just have to laugh\n",
      "you you you you you you you you you you you you you you <EOS>\n",
      "18m 27s (- 549m 44s) (65 3%) 6.3774\n",
      "its in my family you know my grandmother died in an institution\n",
      "i you you the the the the the the the the the the the the the the the the the\n",
      "19m 46s (- 545m 7s) (70 3%) 6.2909\n",
      "why ith dat newth ?\n",
      "i i i i know ? <EOS>\n",
      "21m 7s (- 542m 3s) (75 3%) 6.2401\n",
      "but they would ! dont you see ?\n",
      "you you you you you you you you you you you you you you you you you you you you\n",
      "22m 29s (- 539m 41s) (80 4%) 6.1387\n",
      "yep that thing does nothing for your damage the rest helps a lot too fractals and cps\n",
      "i i i i i i you i you you you you you you you you you you you you\n",
      "23m 45s (- 535m 26s) (85 4%) 6.0356\n",
      "i think hell find that satisfying\n",
      "you know you you know <EOS>\n",
      "25m 6s (- 532m 52s) (90 4%) 6.0603\n",
      "do you know how i felt diz ?\n",
      "i think you think you think you you the the the the the the the the the the the the\n",
      "26m 26s (- 530m 14s) (95 4%) 6.0716\n",
      "what didnt you like about her ?\n",
      "what <EOS>\n",
      "27m 45s (- 527m 27s) (100 5%) 5.9881\n",
      "as a matter of fact i caught a case that goes back to your dayone of the nightingale murders\n",
      "i know you do you know <EOS>\n",
      "29m 5s (- 524m 54s) (105 5%) 6.0612\n",
      "gimme a break mr russo im in show business\n",
      "i dont you you you you you you you you you you you you you you you you you you\n",
      "30m 28s (- 523m 30s) (110 5%) 6.1397\n",
      "no my ship was doing a map of all the suns and\n",
      "i know you i know you i know you i know you i know you i know you i know\n",
      "31m 50s (- 521m 50s) (115 5%) 6.0371\n",
      "do you remember anything unusual happening at the time ?\n",
      "what you dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont\n",
      "33m 9s (- 519m 33s) (120 6%) 6.0512\n",
      "thats what i told them\n",
      "i dont know <EOS>\n",
      "34m 30s (- 517m 35s) (125 6%) 5.8547\n",
      "hello my name is carl\n",
      "you have the name <EOS>\n",
      "35m 49s (- 515m 25s) (130 6%) 5.9415\n",
      "i can say the same to you ! glad i can make you smile\n",
      "i dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont dont\n",
      "37m 9s (- 513m 17s) (135 6%) 6.0271\n",
      "youre on his side all of the sudden ?\n",
      "i know you you you you you you you you you you you you you you you you you you\n",
      "38m 29s (- 511m 27s) (140 7%) 5.9480\n",
      "im sorry sir you okay ?\n",
      "i dont think you think you think you think you think you think you think you think you think you\n",
      "39m 49s (- 509m 34s) (145 7%) 5.9653\n",
      "of the women in this world are named liz\n",
      "i think you know you you be a name <EOS>\n",
      "41m 8s (- 507m 30s) (150 7%) 5.9143\n",
      "thanks bobby and my little round friends too\n",
      "i dont do you dont dont have ? <EOS>\n",
      "42m 27s (- 505m 20s) (155 7%) 5.8809\n",
      "what do you mean hkjs sfjkl afsdj fsfdsaffau ?\n",
      "i know you you you you you you you you you you you you you you you you you you\n",
      "43m 46s (- 503m 21s) (160 8%) 5.9311\n",
      "days and we bring it back home\n",
      "i think you have to be to be to be to be to be to be to be to be\n",
      "45m 6s (- 501m 37s) (165 8%) 5.7536\n",
      "now left and thats it in front of you\n",
      "i know <EOS>\n",
      "46m 25s (- 499m 43s) (170 8%) 5.9712\n",
      "rufus for christs sake get up\n",
      "i have the little <EOS>\n",
      "47m 45s (- 498m 1s) (175 8%) 5.8178\n",
      "forget it we work for it we keep it\n",
      "i know i know i know i know i know i know i know i know i know i know\n",
      "49m 4s (- 496m 15s) (180 9%) 5.8332\n",
      "i want to finish what i started i want to finish the game\n",
      "you be a little <EOS>\n",
      "50m 22s (- 494m 15s) (185 9%) 5.8082\n",
      "touche honey yeah ive been doing a little hacking here which ive got every reason as you well know\n",
      "i dont know <EOS>\n"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 2000\n",
    "epoch = 0\n",
    "print_every = 5\n",
    "gamma = .99\n",
    "learning_rate = 0.001\n",
    "decoder_learning_ratio = 4.0\n",
    "# Initialize optimizers and criterion\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(),\n",
    "                               lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), \n",
    "                               lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "escheduler = optim.lr_scheduler.StepLR(encoder_optimizer, \n",
    "                                       step_size=print_every, gamma=gamma) \n",
    "\n",
    "dscheduler = optim.lr_scheduler.StepLR(decoder_optimizer, \n",
    "                                        step_size=print_every, gamma=gamma) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "    \n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        print(sample())\n",
    "        #print(chat(\"what are you doing ?\"))\n",
    "        \n",
    "    escheduler.step()\n",
    "    dscheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LuongAttnDecoderRNN(\n",
       "  (embedding): Embedding(28708, 512)\n",
       "  (embedding_dropout): Dropout(p=0.1)\n",
       "  (gru): GRU(512, 512, num_layers=2, dropout=0.1)\n",
       "  (concat): Linear(in_features=1024, out_features=512)\n",
       "  (out): Linear(in_features=512, out_features=28708)\n",
       "  (attn): Attn(\n",
       "    (attn): Linear(in_features=512, out_features=512)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"_backwardseq2seq_2L_512h_bi_\"\n",
    "\n",
    "torch.save(encoder.state_dict(), \"saved_params/encoder\"+name+\".pth\")\n",
    "torch.save(decoder.state_dict(), \"saved_params/decoder\"+name+\".pth\")\n",
    "\n",
    "encodercpu = encoder.cpu()\n",
    "decodercpu = decoder.cpu()\n",
    "\n",
    "torch.save(encodercpu.state_dict(), \"saved_params/encoder\"+name+\"cpu.pth\")\n",
    "torch.save(decodercpu.state_dict(), \"saved_params/decoder\"+name+\"cpu.pth\")\n",
    "\n",
    "encoder.cuda()\n",
    "decoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"_backwardseq2seq_2L_512h_bi_\"\n",
    "encoder.load_state_dict(torch.load(\"saved_params/encoder\"+name+\".pth\"))\n",
    "decoder.load_state_dict(torch.load(\"saved_params/decoder\"+name+\".pth\"))\n",
    "#encoder.cuda()\n",
    "#decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(put_seq, max_length=MAX_SENT_LENGTH):\n",
    "\n",
    "    #input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "    #input_lengths = [len(input_seq)]\n",
    "    #input_seqs = [indexesFromSentence(lang, input_seq)]\n",
    "    #input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "    #[torch.cuda.LongTensor of size 9x1 (GPU 0)]\n",
    "    \n",
    "    put_seqs = []\n",
    "\n",
    "    print(put_seq)\n",
    "    put_seqs.append(indexesFromSentence(lang, put_seq))\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    put_lengths = [len(s) for s in put_seqs]\n",
    "    put_padded = [pad_seq(s, max(put_lengths)) for s in put_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    put_batches = Variable(torch.LongTensor(put_padded)).transpose(0, 1)\n",
    "    \n",
    "    if use_cuda:\n",
    "        \n",
    "        put_batches =  put_batches.cuda()\n",
    "    \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_puts, encoder_hid = encoder(put_batches, put_lengths, None)\n",
    "    #input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_put = Variable(torch.LongTensor([lang.SOS_token]))\n",
    "    decoder_hid = encoder_hid[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    #max_target_length = max(target_lengths)\n",
    "    #all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if use_cuda:\n",
    "        decoder_put = decoder_put.cuda()\n",
    "    \n",
    "    decoded_words = []\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        \n",
    "        decoder_put, decoder_hid, decoder_attention = decoder(\n",
    "            decoder_put, decoder_hid, encoder_puts\n",
    "        )\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_put.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == lang.EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "    \n",
    "    return ' '.join(decoded_words)\n",
    "        \n",
    "chat(\"what are you doing ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(max_length=MAX_SENT_LENGTH):\n",
    "  \n",
    "    in_seqs = []\n",
    "    pair = random.choice(pairs)\n",
    "    in_seqs.append(indexesFromSentence(lang,pair[0]))\n",
    "    print(pair[0])\n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    in_lengths = [len(s) for s in in_seqs]\n",
    "    in_padded = [pad_seq(s, max(in_lengths)) for s in in_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    in_var = Variable(torch.LongTensor(in_padded)).transpose(0, 1)\n",
    "    \n",
    "    if use_cuda:\n",
    "        in_var = in_var.cuda()\n",
    "    \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(in_var, in_lengths, None)\n",
    "    #input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([lang.SOS_token]))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    #print(decoder_hidden.size())\n",
    "    # Move new Variables to CUDA\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    decoded_words = []\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        \n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == lang.EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#REVERSE DIRECTION\n",
    "\n",
    "pairs = final_pairs\n",
    "\n",
    "len(pairs)\n",
    "\n",
    "reverse_pairs = []\n",
    "\n",
    "for pair in pairs:\n",
    "    reverse_pairs.append([pair[1],pair[0]])\n",
    "    \n",
    "pairs = reverse_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonnys and rivers only bbq places i know about in gnv',\n",
       " 'why are you eating at sonnys ?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is this working ?\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -7.7843e-02 -1.7828e-01 -9.6904e-01  ...  -4.5919e-02  8.6338e-01 -1.0753e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -8.1155e-02 -1.6344e-01 -9.5222e-01  ...  -4.4829e-02  9.8395e-01 -8.8712e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -8.3334e-02 -1.4063e-01 -4.5165e-01  ...  -4.2915e-02  9.9480e-01 -5.2019e-01\n",
      "\n",
      "( 3 ,.,.) = \n",
      " -8.4853e-02 -1.1292e-01 -2.9206e-05  ...  -4.1338e-02  9.9724e-01 -2.1333e-01\n",
      "[torch.cuda.FloatTensor of size 4x1x512 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.LongTensor\u001b[0m), but expected (torch.cuda.FloatTensor source, int dim, torch.cuda.LongTensor index)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-38f5f3764924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0mchat_using_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is this working ?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-38f5f3764924>\u001b[0m in \u001b[0;36mchat_using_beam_search\u001b[0;34m(input_seq, max_length)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcandidates_for_next_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mnext_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_word_and_get_new_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;31m# todo: does python have flatMap(...) like scala? would be way easier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnext_can\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-38f5f3764924>\u001b[0m in \u001b[0;36mfeed_word_and_get_new_candidates\u001b[0;34m(self, rnn_decoder, beam_width)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             decoder_output, decoder_hidden, decoder_attention = rnn_decoder(\n\u001b[0;32m---> 38\u001b[0;31m                 next_word_var, self.hidden_state, self.encoder_outputs)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogSoftMaxFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carson/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fb0cb863dc7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#hidden = self.hidden0.repeat(1, batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# S=1 x B x N, view is like reshape()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carson/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carson/.local/lib/python3.5/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carson/.local/lib/python3.5/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.LongTensor\u001b[0m), but expected (torch.cuda.FloatTensor source, int dim, torch.cuda.LongTensor index)"
     ]
    }
   ],
   "source": [
    "# holds a candidate to be used in beam search.\n",
    "# we need to store the current log_prob, hidden_state, decoded_words, \n",
    "\n",
    "logSoftMaxFunc = nn.LogSoftmax()\n",
    "realSoftMax = nn.Softmax()\n",
    "\n",
    "class BeamSearchCandidate:\n",
    "    \n",
    "    # should start using [SOS]\n",
    "    def __init__(self, encoder_outputs, hidden_state, next_word_idx, log_prob, decoded_words, is_eos):\n",
    "        self.encoder_outputs = encoder_outputs\n",
    "        self.hidden_state = hidden_state\n",
    "        self.seq_log_prob = log_prob # init\n",
    "        self.decoded_seq_idx = decoded_words\n",
    "        self.next_word_idx = next_word_idx\n",
    "        self.is_eos = is_eos\n",
    "    \n",
    "    # return a list of BeamSearchCandidate by feeding next word into rnn_decoder \n",
    "    def feed_word_and_get_new_candidates(self, rnn_decoder, beam_width):\n",
    "        \n",
    "        # if you've already reached the EOS, don't return anymore\n",
    "        # todo: add some parameters for beam search to fix the length problem\n",
    "        if (self.is_eos):\n",
    "            print(\"Got EOS output for this candidate already...not creating more candidates\")\n",
    "            return [self]\n",
    "        \n",
    "        else:      \n",
    "            \n",
    "            next_word_var = Variable(torch.LongTensor([self.next_word_idx]))\n",
    "            \n",
    "            if use_cuda:\n",
    "                next_word_var.cuda()\n",
    "                self.hidden_state.cuda()\n",
    "                self.encoder_outputs.cuda()\n",
    "                \n",
    "            print(self.encoder_outputs)\n",
    "            decoder_output, decoder_hidden, decoder_attention = rnn_decoder(\n",
    "                next_word_var, self.hidden_state, self.encoder_outputs)\n",
    "\n",
    "            log_probs = logSoftMaxFunc(decoder_output)\n",
    "\n",
    "            top_log_probs, top_i = log_probs.data.topk(beam_width)\n",
    "\n",
    "            new_candidates = []\n",
    "            for b in range(0, beam_width):\n",
    "                curr_word = top_i[0][b]\n",
    "                curr_word_log_prob = top_log_probs[0][b]\n",
    "                is_eos_tmp = False\n",
    "                if (curr_word == lang.EOS_token):\n",
    "                    is_eos_tmp = True\n",
    "                # update log prob\n",
    "                new_log_prob = self.seq_log_prob + curr_word_log_prob\n",
    "                # update word seq\n",
    "                new_decoded_word_seq = list(self.decoded_seq_idx)\n",
    "                new_decoded_word_seq.append(curr_word)\n",
    "                # create new candidate and append to list\n",
    "                new_beam_search_candidate = BeamSearchCandidate(self.encoder_outputs, decoder_hidden, curr_word, new_log_prob, new_decoded_word_seq, is_eos_tmp)\n",
    "                new_candidates.append(new_beam_search_candidate)\n",
    "\n",
    "            return new_candidates\n",
    "\n",
    "    # return the decoded sequence along with it's probability \n",
    "    # could just keep it as log_prob since this is probably going to be really small\n",
    "    def get_decoded_words_and_prob(self):\n",
    "        decoded_words = []\n",
    "        for idx in self.decoded_seq_idx:\n",
    "            decoded_words.append(lang.index2word[idx])\n",
    "        return (decoded_words, np.exp(self.seq_log_prob))\n",
    "\n",
    "def chat_using_beam_search(input_seq, max_length=MAX_SENT_LENGTH):\n",
    "\n",
    "    #input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "    #input_lengths = [len(input_seq)]\n",
    "    #input_seqs = [indexesFromSentence(lang, input_seq)]\n",
    "    #input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "    #[torch.cuda.LongTensor of size 9x1 (GPU 0)]\n",
    "    \n",
    "    input_seqs = []\n",
    "\n",
    "    print(input_seq)\n",
    "    input_seqs.append(indexesFromSentence(lang, input_seq))\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    \n",
    "    if use_cuda:\n",
    "        input_var = input_var.cuda()\n",
    "    \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_var, input_lengths, None)\n",
    "    #encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    #input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([lang.SOS_token]))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    ################# define beam search constants ######################\n",
    "    \n",
    "    beam_width = 3  # how many words to explore at each stage\n",
    "    max_candidates = 10 # max number of sequences you want to consider at one time\n",
    "    num_iterations = 10 # this should really be equal to the max length ???\n",
    "    num_final_candidates = 5 # number of candidates you actually want to return\n",
    "    \n",
    "    ################ start beam search ##############################\n",
    "    \n",
    "    # initially we feed in SOS, we have no words in output so far, and log prob is 1.0 \n",
    "    starting_candidate = BeamSearchCandidate(encoder_outputs, decoder_hidden, lang.SOS_token, 1.0, [], False)    \n",
    "    curr_candidates = [starting_candidate]\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        candidates_for_next_iteration = []\n",
    "        for can in curr_candidates:\n",
    "            next_candidates = can.feed_word_and_get_new_candidates(decoder, beam_width)\n",
    "            # todo: does python have flatMap(...) like scala? would be way easier\n",
    "            for next_can in next_candidates:\n",
    "                candidates_for_next_iteration.append(next_can)\n",
    "        curr_candidates = candidates_for_next_iteration\n",
    "        if (len(curr_candidates) > max_candidates):\n",
    "            # prune the list of candidates down, sort by log prob of sequence\n",
    "            # could be sped up using a priority queue or something ?\n",
    "            print(\"We have {} candidates but the max is {}. Only keeping the top {} candidates\".format(len(curr_candidates), max_candidates, max_candidates))  \n",
    "            curr_candidates = sorted(curr_candidates, key = lambda can : can.seq_log_prob, reverse=True)[0:max_candidates]\n",
    "    \n",
    "    # sort by log prob once more for final output\n",
    "    final_candidates = sorted(curr_candidates, key = lambda can : can.seq_log_prob, reverse=True)[0:num_final_candidates]\n",
    "    \n",
    "    for can in final_candidates:\n",
    "        print(can.get_decoded_words_and_prob())\n",
    "\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "    \n",
    "    return final_candidates\n",
    "        \n",
    "chat_using_beam_search(\"is this working ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "you are ?\n",
    "i know im got to be <UNK> a little <UNK> <UNK> <UNK> <UNK> a little <UNK> <UNK> <UNK> a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  6749   4702   3820  17427   7921\n",
       " 17823  12660  26822  23654      2\n",
       " 26504   2791  20437      2      0\n",
       " 10831  19227  17412      0      0\n",
       " 23730  26520  26664      0      0\n",
       "  7921    251  11707      0      0\n",
       "  9743  26822   1696      0      0\n",
       " 20229   7475   5651      0      0\n",
       " 19240  15364  20434      0      0\n",
       " 17275   7838      2      0      0\n",
       "  9367   1628      0      0      0\n",
       "  4404   2791      0      0      0\n",
       " 23264   8045      0      0      0\n",
       " 20561  23916      0      0      0\n",
       " 20229  11864      0      0      0\n",
       " 26289  20229      0      0      0\n",
       " 22168   1696      0      0      0\n",
       " 25704   7341      0      0      0\n",
       "  6397      2      0      0      0\n",
       "     2      0      0      0      0\n",
       "[torch.cuda.LongTensor of size 20x5 (GPU 0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batches, input_lengths, target_batches, target_lengths = random_batch(5)\n",
    "input_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18331, 26520, 27686, 23722, 20434, 2]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(lang, \"are you my friend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
